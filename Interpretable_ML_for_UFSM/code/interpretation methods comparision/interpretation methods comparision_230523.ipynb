{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.python/current/lib/python3.10/site-packages/shap/utils/_clustering.py:35: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def _pt_shuffle_rec(i, indexes, index_mask, partition_tree, M, pos):\n",
      "/home/codespace/.python/current/lib/python3.10/site-packages/shap/utils/_clustering.py:54: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def delta_minimization_order(all_masks, max_swap_size=100, num_passes=2):\n",
      "/home/codespace/.python/current/lib/python3.10/site-packages/shap/utils/_clustering.py:63: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def _reverse_window(order, start, length):\n",
      "/home/codespace/.python/current/lib/python3.10/site-packages/shap/utils/_clustering.py:69: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def _reverse_window_score_gain(masks, order, start, length):\n",
      "/home/codespace/.python/current/lib/python3.10/site-packages/shap/utils/_clustering.py:77: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def _mask_delta_score(m1, m2):\n",
      "/home/codespace/.python/current/lib/python3.10/site-packages/shap/links.py:5: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def identity(x):\n",
      "/home/codespace/.python/current/lib/python3.10/site-packages/shap/links.py:10: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def _identity_inverse(x):\n",
      "/home/codespace/.python/current/lib/python3.10/site-packages/shap/links.py:15: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def logit(x):\n",
      "/home/codespace/.python/current/lib/python3.10/site-packages/shap/links.py:20: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def _logit_inverse(x):\n",
      "/home/codespace/.python/current/lib/python3.10/site-packages/shap/utils/_masked_model.py:363: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def _build_fixed_single_output(averaged_outs, last_outs, outputs, batch_positions, varying_rows, num_varying_rows, link, linearizing_weights):\n",
      "/home/codespace/.python/current/lib/python3.10/site-packages/shap/utils/_masked_model.py:385: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def _build_fixed_multi_output(averaged_outs, last_outs, outputs, batch_positions, varying_rows, num_varying_rows, link, linearizing_weights):\n",
      "/home/codespace/.python/current/lib/python3.10/site-packages/shap/utils/_masked_model.py:428: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def _init_masks(cluster_matrix, M, indices_row_pos, indptr):\n",
      "/home/codespace/.python/current/lib/python3.10/site-packages/shap/utils/_masked_model.py:439: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def _rec_fill_masks(cluster_matrix, indices_row_pos, indptr, indices, M, ind):\n",
      "/home/codespace/.python/current/lib/python3.10/site-packages/shap/maskers/_tabular.py:186: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def _single_delta_mask(dind, masked_inputs, last_mask, data, x, noop_code):\n",
      "/home/codespace/.python/current/lib/python3.10/site-packages/shap/maskers/_tabular.py:197: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def _delta_masking(masks, x, curr_delta_inds, varying_rows_out,\n",
      "/home/codespace/.python/current/lib/python3.10/site-packages/shap/maskers/_image.py:175: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def _jit_build_partition_tree(xmin, xmax, ymin, ymax, zmin, zmax, total_ywidth, total_zwidth, M, clustering, q):\n",
      "/home/codespace/.python/current/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/codespace/.python/current/lib/python3.10/site-packages/shap/explainers/_partition.py:676: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def lower_credit(i, value, M, values, clustering):\n",
      "\u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "\u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.sparse.linalg import cg\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import shap\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import time\n",
    "import datetime\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import sklearn.tree \n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "import shap\n",
    "import xgboost\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pylab as pl\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import LinearSVC\n",
    "import matplotlib.pyplot as plt\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from skopt import gp_minimize\n",
    "from skopt.space import Real, Integer\n",
    "from skopt.utils import use_named_args\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of zero: 14402\n",
      "number of one: 2466\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FID_</th>\n",
       "      <th>average_max_rainfall</th>\n",
       "      <th>average_2hr_rainfall</th>\n",
       "      <th>average_72hr_rainfall</th>\n",
       "      <th>distance to coast</th>\n",
       "      <th>EV</th>\n",
       "      <th>TWI</th>\n",
       "      <th>DTW</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.032337</td>\n",
       "      <td>0.173904</td>\n",
       "      <td>0.540760</td>\n",
       "      <td>1399.816133</td>\n",
       "      <td>3.449655</td>\n",
       "      <td>2032.268709</td>\n",
       "      <td>7.511351</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.036179</td>\n",
       "      <td>0.173910</td>\n",
       "      <td>0.540058</td>\n",
       "      <td>1452.270984</td>\n",
       "      <td>3.351578</td>\n",
       "      <td>2289.101516</td>\n",
       "      <td>7.397089</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1.034249</td>\n",
       "      <td>0.173900</td>\n",
       "      <td>0.540413</td>\n",
       "      <td>1427.899396</td>\n",
       "      <td>3.355286</td>\n",
       "      <td>2170.271564</td>\n",
       "      <td>7.548316</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1.040040</td>\n",
       "      <td>0.173918</td>\n",
       "      <td>0.539438</td>\n",
       "      <td>1487.814834</td>\n",
       "      <td>3.489952</td>\n",
       "      <td>2261.629379</td>\n",
       "      <td>8.816202</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1.038104</td>\n",
       "      <td>0.173915</td>\n",
       "      <td>0.539721</td>\n",
       "      <td>1472.312893</td>\n",
       "      <td>3.421316</td>\n",
       "      <td>2262.551560</td>\n",
       "      <td>9.006661</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16863</th>\n",
       "      <td>17497</td>\n",
       "      <td>0.973075</td>\n",
       "      <td>0.173802</td>\n",
       "      <td>0.558195</td>\n",
       "      <td>288.711012</td>\n",
       "      <td>2.471787</td>\n",
       "      <td>995.830005</td>\n",
       "      <td>5.545090</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16864</th>\n",
       "      <td>17498</td>\n",
       "      <td>0.972212</td>\n",
       "      <td>0.173765</td>\n",
       "      <td>0.558101</td>\n",
       "      <td>301.895848</td>\n",
       "      <td>2.573513</td>\n",
       "      <td>1024.210310</td>\n",
       "      <td>7.424834</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16865</th>\n",
       "      <td>17499</td>\n",
       "      <td>0.974931</td>\n",
       "      <td>0.173857</td>\n",
       "      <td>0.558490</td>\n",
       "      <td>242.731595</td>\n",
       "      <td>2.150453</td>\n",
       "      <td>890.199884</td>\n",
       "      <td>6.642009</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16866</th>\n",
       "      <td>17500</td>\n",
       "      <td>0.976530</td>\n",
       "      <td>0.173897</td>\n",
       "      <td>0.558775</td>\n",
       "      <td>224.446030</td>\n",
       "      <td>2.170294</td>\n",
       "      <td>786.371904</td>\n",
       "      <td>6.314220</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16867</th>\n",
       "      <td>17501</td>\n",
       "      <td>1.063577</td>\n",
       "      <td>0.175497</td>\n",
       "      <td>0.570720</td>\n",
       "      <td>922.927039</td>\n",
       "      <td>2.928563</td>\n",
       "      <td>2973.308531</td>\n",
       "      <td>4.465188</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16868 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        FID_  average_max_rainfall  average_2hr_rainfall   \n",
       "0          0              1.032337              0.173904  \\\n",
       "1          1              1.036179              0.173910   \n",
       "2          2              1.034249              0.173900   \n",
       "3          3              1.040040              0.173918   \n",
       "4          4              1.038104              0.173915   \n",
       "...      ...                   ...                   ...   \n",
       "16863  17497              0.973075              0.173802   \n",
       "16864  17498              0.972212              0.173765   \n",
       "16865  17499              0.974931              0.173857   \n",
       "16866  17500              0.976530              0.173897   \n",
       "16867  17501              1.063577              0.175497   \n",
       "\n",
       "       average_72hr_rainfall  distance to coast        EV          TWI   \n",
       "0                   0.540760        1399.816133  3.449655  2032.268709  \\\n",
       "1                   0.540058        1452.270984  3.351578  2289.101516   \n",
       "2                   0.540413        1427.899396  3.355286  2170.271564   \n",
       "3                   0.539438        1487.814834  3.489952  2261.629379   \n",
       "4                   0.539721        1472.312893  3.421316  2262.551560   \n",
       "...                      ...                ...       ...          ...   \n",
       "16863               0.558195         288.711012  2.471787   995.830005   \n",
       "16864               0.558101         301.895848  2.573513  1024.210310   \n",
       "16865               0.558490         242.731595  2.150453   890.199884   \n",
       "16866               0.558775         224.446030  2.170294   786.371904   \n",
       "16867               0.570720         922.927039  2.928563  2973.308531   \n",
       "\n",
       "            DTW  label  \n",
       "0      7.511351      1  \n",
       "1      7.397089      1  \n",
       "2      7.548316      1  \n",
       "3      8.816202      1  \n",
       "4      9.006661      1  \n",
       "...         ...    ...  \n",
       "16863  5.545090      0  \n",
       "16864  7.424834      0  \n",
       "16865  6.642009      0  \n",
       "16866  6.314220      0  \n",
       "16867  4.465188      0  \n",
       "\n",
       "[16868 rows x 9 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 导入数据\n",
    "\n",
    "data = pd.read_csv('/Users/jiqiang/Nutstore Files/DULT/小论文/第一篇小论文/数据/jh_z/model training_pc_20230521/final_data_input_important_16869.csv')\n",
    "# C:/Jiqiang/jh_z/jh_z/model training_pc/final_data_input_important.csv\n",
    "# /Users/jiqiang/Nutstore Files/DULT/小论文/第一篇小论文/数据/jh_z/model training_pc_20230521/final_data_input_important.csv\n",
    "df= pd.DataFrame(data)\n",
    "counts = df['label'].value_counts()\n",
    "num_zeros = counts[0]\n",
    "num_ones = counts[1]\n",
    "print(\"number of zero:\",num_zeros)\n",
    "print(\"number of one:\",num_ones)\n",
    "\n",
    "\n",
    "# 从总数据中抽取1000个1和1000个0作为训练和测试，剩下的作为预测集\n",
    "# 随机抽取label为0和1的数据各1000个\n",
    "df1 = pd.concat([df[df['label']==0].sample(n=1000),df[df['label']==1].sample(n=1000)]) # 训练集和测试集\n",
    "print(df1)\n",
    "\n",
    "# 删除已经抽取的数据，剩下的放入df2中\n",
    "df2 = df.drop(df1.index) # 剩下的数据作为预测集\n",
    "df2\n",
    "\n",
    "# 固定训练集、测试集、预测集，将其分别输出到CSV文件中\n",
    "df1.to_csv('train_test_data.csv', index=False)\n",
    "df2.to_csv('predict_data.csv', index=False)\n",
    "\n",
    "# 用df1中的数据划分训练集和测试集，输出到CSV文件中，随后分别为训练集和测试集输入特征进行标准化\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 提取最后一列并命名为“y”\n",
    "Y = df1.iloc[:, -1]\n",
    "Y.name = 'y'\n",
    "\n",
    "\n",
    "X_train_orgin, X_test_orgin, Y_train_orgin, Y_test_orgin = train_test_split(df1.drop('label', axis=1), df1['label'], test_size=0.2, random_state=42)\n",
    "\n",
    "# 输出训练集和测试集\n",
    "X_train_Y_train = pd.concat([X_train_orgin, Y_train_orgin],axis=1)\n",
    "X_test_Y_test = pd.concat([X_test_orgin, Y_test_orgin],axis=1)\n",
    "\n",
    "X_train_Y_train.to_csv('train_data.csv', index=False)\n",
    "X_test_Y_test.to_csv('test_data.csv', index=False)\n",
    "\n",
    "# 训练集和测试集的特征标准化\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "# 提取除最后一列和第一列单元名以外的所有列并命名为“X”\n",
    "X_train_orgin_dropFID = X_train_orgin.iloc[:, 1:]\n",
    "X_test_orgin_dropFID = X_test_orgin.iloc[:, 1:]\n",
    "X_pred = df2.iloc[:, 1:-1]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_orgin_dropFID)\n",
    "X_test_scaled = scaler.transform(X_test_orgin_dropFID)\n",
    "X_pred_scaled = scaler.transform(X_pred)\n",
    "\n",
    "# 将标准化后的数据输出到新的数据框中\n",
    "X_train = pd.DataFrame(X_train_scaled, columns=X_train_orgin_dropFID.columns, index=X_train_orgin_dropFID.index)\n",
    "X_test = pd.DataFrame(X_test_scaled, columns=X_test_orgin_dropFID.columns,  index=X_test_orgin_dropFID.index)\n",
    "X_pred = pd.DataFrame(X_pred_scaled, columns=X_pred.columns, index=X_pred.index)\n",
    "\n",
    "Y_train = Y_train_orgin\n",
    "Y_test = Y_test_orgin\n",
    "\n",
    "# 模型训练\n",
    "def print_test_accuracy(f):\n",
    "    print(\"Accuracy = {0}%\".format(100*np.sum(f(X_test) == Y_test)/len(Y_test)))\n",
    "    time.sleep(0.5) # to let the print get out before any progress bars\n",
    "\n",
    "def print_train_accuracy(f):\n",
    "    print(\"Accuracy = {0}%\".format(100*np.sum(f(X_train) == Y_train)/len(Y_train)))\n",
    "    time.sleep(0.5) # to let the print get out before any progress bars\n",
    "shap.initjs()\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_curve, auc\n",
    "\n",
    "# 将数据分为X_train, Y_train, X_test, Y_test\n",
    "\n",
    "# 定义XGBoost模型\n",
    "xgb_model = xgb.XGBClassifier()\n",
    "\n",
    "# 定义参数空间\n",
    "param_grid = {\n",
    "    'max_depth': [3, 4, 5],\n",
    "    'learning_rate': [0.1, 0.01],\n",
    "    'n_estimators': [50, 100]\n",
    "}\n",
    "\n",
    "# 定义5折交叉验证策略\n",
    "cv = StratifiedKFold(n_splits=5)\n",
    "\n",
    "# 使用GridSearchCV进行自动调参和交叉验证\n",
    "grid_search_xgb = GridSearchCV(xgb_model,\n",
    "                           param_grid=param_grid,\n",
    "                           scoring='accuracy',\n",
    "                           cv=cv,\n",
    "                           n_jobs=-1)\n",
    "\n",
    "grid_search_xgb.fit(X_train, Y_train)\n",
    "\n",
    "# 输出每一折的训练集和测试集准确率\n",
    "for i in range(5):\n",
    "    print(\"Fold \", i+1)\n",
    "    train_index, test_index = list(cv.split(X_train, Y_train))[i]\n",
    "    print(\"Training Accuracy: \", accuracy_score(Y_train.iloc[train_index], grid_search_xgb.predict(X_train.iloc[train_index])))\n",
    "    print(\"Testing Accuracy: \", accuracy_score(Y_train.iloc[test_index], grid_search_xgb.predict(X_train.iloc[test_index])))\n",
    "\n",
    "# 输出模型在训练集和测试集上的精准率、召回率、F1、ROC曲线和AUC曲线平均值\n",
    "print(\"Training Accuracy: \", accuracy_score(Y_train, grid_search_xgb.predict(X_train)).round(3))\n",
    "print(\"Testing Accuracy: \", accuracy_score(Y_test, grid_search_xgb.predict(X_test)).round(3))\n",
    "print(\"Training Precision: \", precision_score(Y_train, grid_search_xgb.predict(X_train)).round(3))\n",
    "print(\"Testing Precision: \", precision_score(Y_test, grid_search_xgb.predict(X_test)).round(3))\n",
    "print(\"Training Recall: \", recall_score(Y_train, grid_search_xgb.predict(X_train)).round(3))\n",
    "print(\"Testing Recall: \", recall_score(Y_test, grid_search_xgb.predict(X_test)).round(3))\n",
    "print(\"Training F1 Score: \", f1_score(Y_train, grid_search_xgb.predict(X_train)).round(3))\n",
    "print(\"Testing F1Score: \", f1_score(Y_test, grid_search_xgb.predict(X_test)).round(3))\n",
    "\n",
    "# 计算ROC曲线和AUC曲线\n",
    "fpr_train, tpr_train, _ = roc_curve(Y_train, grid_search_xgb.predict_proba(X_train)[:, 1])\n",
    "fpr_test, tpr_test, _ = roc_curve(Y_test, grid_search_xgb.predict_proba(X_test)[:, 1])\n",
    "roc_auc_train = auc(fpr_train, tpr_train)\n",
    "roc_auc_test = auc(fpr_test, tpr_test)\n",
    "\n",
    "# 输出ROC曲线和AUC曲线平均值\n",
    "print(\"Training ROC AUC: \", roc_auc_train.round(3))\n",
    "print(\"Testing ROC AUC: \", roc_auc_test.round(3)) \n",
    "\n",
    "# nn\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_curve, auc\n",
    "\n",
    "# 定义多层感知机模型\n",
    "mlp = MLPClassifier()\n",
    "\n",
    "# 定义参数网格\n",
    "param_grid = {\n",
    "    'hidden_layer_sizes': [(50,), (100,), (50, 50), (100, 100)],\n",
    "    'activation': ['logistic', 'tanh', 'relu'],\n",
    "    'solver': ['lbfgs', 'adam'],\n",
    "    'alpha': [0.0001, 0.001],\n",
    "    'learning_rate': ['constant', 'adaptive']\n",
    "}\n",
    "\n",
    "# 定义5折交叉验证器\n",
    "cv = StratifiedKFold(n_splits=5)\n",
    "\n",
    "# 定义网格搜索器\n",
    "grid_search_mlp = GridSearchCV(mlp, param_grid=param_grid,\n",
    "                           cv=cv, scoring='roc_auc')\n",
    "\n",
    "# 训练模型并进行自动调参\n",
    "grid_search_mlp.fit(X_train, Y_train)\n",
    "\n",
    "# 输出最佳参数组合和对应的AUC值\n",
    "print('Best parameters:', grid_search_mlp.best_params_)\n",
    "print('Best AUC:', grid_search_mlp.best_score_)\n",
    "\n",
    "# 计算模型在训练集和测试集上的精准率、召回率、F1、ROC曲线和AUC曲线等指标，并打印结果\n",
    "Y_train_pred = grid_search_mlp.predict(X_train)\n",
    "Y_test_pred = grid_search_mlp.predict(X_test)\n",
    "\n",
    "print('Training accuracy:', accuracy_score(Y_train, Y_train_pred))\n",
    "print('Testing accuracy:', accuracy_score(Y_test, Y_test_pred))\n",
    "\n",
    "print('Training precision:', precision_score(Y_train, Y_train_pred))\n",
    "print('Testing precision:', precision_score(Y_test, Y_test_pred))\n",
    "\n",
    "print('Training recall:', recall_score(Y_train, Y_train_pred))\n",
    "print('Testing recall:', recall_score(Y_test, Y_test_pred))\n",
    "\n",
    "print('Training F1 score:', f1_score(Y_train, Y_train_pred))\n",
    "print('Testing F1 score:', f1_score(Y_test, Y_test_pred))\n",
    "\n",
    "fpr_train, tpr_train, _ = roc_curve(Y_train, grid_search_mlp.predict_proba(X_train)[:, 1])\n",
    "fpr_test, tpr_test, _ = roc_curve(Y_test, grid_search_mlp.predict_proba(X_test)[:, 1])\n",
    "\n",
    "print('Training AUC:', auc(fpr_train, tpr_train))\n",
    "print('Testing AUC:', auc(fpr_test, tpr_test))\n",
    "\n",
    "# LR\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_curve, auc\n",
    "import pandas as pd\n",
    "\n",
    "# 定义逻辑回归模型和参数网格\n",
    "model = LogisticRegression()\n",
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10]}\n",
    "\n",
    "# 使用GridSearchCV进行自动调参和5折交叉验证\n",
    "grid_search_lr = GridSearchCV(model, param_grid=param_grid, cv=5)\n",
    "grid_search_lr.fit(X_train, Y_train)\n",
    "\n",
    "# 打印最佳参数和最佳得分\n",
    "print('Best Parameters:', grid_search_lr.best_params_)\n",
    "print('Best Score:', grid_search_lr.best_score_)\n",
    "\n",
    "# 在训练集上评估模型\n",
    "Y_train_pred = grid_search_lr.predict(X_train)\n",
    "print('Training Accuracy:', accuracy_score(Y_train, Y_train_pred))\n",
    "print('Training Precision:', precision_score(Y_train, Y_train_pred))\n",
    "print('Training Recall:', recall_score(Y_train, Y_train_pred))\n",
    "print('Training F1 Score:', f1_score(Y_train, Y_train_pred))\n",
    "\n",
    "# 在测试集上评估模型\n",
    "Y_test_pred = grid_search_lr.predict(X_test)\n",
    "print('Testing Accuracy:', accuracy_score(Y_test, Y_test_pred))\n",
    "print('Testing Precision:', precision_score(Y_test, Y_test_pred))\n",
    "print('Testing Recall:', recall_score, Y_test_pred)\n",
    "print('Testing F1 Score:', f1_score(Y_test, Y_test_pred))\n",
    "\n",
    "# 绘制ROC曲线和计算AUC\n",
    "fpr, tpr, thresholds = roc_curve(Y_test, grid_search_lr.predict_proba(X_test)[:, 1])\n",
    "roc_auc = auc(fpr, tpr)\n",
    "plt.plot(fpr, tpr, label='ROC Curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "# 将LR, XGB, NN的模型性能进行对比\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, auc\n",
    "\n",
    "# 训练三个机器学习模型并预测测试集\n",
    "model_lr = grid_search_lr\n",
    "model_xgb = grid_search_xgb\n",
    "model_mlp = grid_search_mlp\n",
    "\n",
    "Y_test_pred1 = model_lr.predict(X_test)\n",
    "Y_test_pred2 = model_xgb.predict(X_test)\n",
    "Y_test_pred3 = model_mlp.predict(X_test)\n",
    "\n",
    "# 计算评价指标\n",
    "accuracy_train1 = accuracy_score(Y_train, model_lr.predict(X_train))\n",
    "accuracy_train2 = accuracy_score(Y_train, model_xgb.predict(X_train))\n",
    "accuracy_train3 = accuracy_score(Y_train, model_mlp.predict(X_train))\n",
    "\n",
    "accuracy_test1 = accuracy_score(Y_test, model_lr.predict(X_test))\n",
    "accuracy_test2 = accuracy_score(Y_test, model_xgb.predict(X_test))\n",
    "accuracy_test3 = accuracy_score(Y_test, model_mlp.predict(X_test))\n",
    "\n",
    "precision_train1 = precision_score(Y_train, model_lr.predict(X_train))\n",
    "precision_train2 = precision_score(Y_train, model_xgb.predict(X_train))\n",
    "precision_train3 = precision_score(Y_train, model_mlp.predict(X_train))\n",
    "\n",
    "precision_test1 = precision_score(Y_test, Y_test_pred1)\n",
    "precision_test2 = precision_score(Y_test, Y_test_pred2)\n",
    "precision_test3 = precision_score(Y_test, Y_test_pred3)\n",
    "\n",
    "recall_train1 = recall_score(Y_train, model_lr.predict(X_train))\n",
    "recall_train2 = recall_score(Y_train, model_xgb.predict(X_train))\n",
    "recall_train3 = recall_score(Y_train, model_mlp.predict(X_train))\n",
    "\n",
    "recall_test1 = recall_score(Y_test, Y_test_pred1)\n",
    "recall_test2 = recall_score(Y_test, Y_test_pred2)\n",
    "recall_test3 = recall_score(Y_test, Y_test_pred3)\n",
    "\n",
    "f1score_train1 = f1_score(Y_train, model_lr.predict(X_train))\n",
    "f1score_train2 = f1_score(Y_train, model_xgb.predict(X_train))\n",
    "f1score_train3 = f1_score(Y_train, model_mlp.predict(X_train))\n",
    "\n",
    "f1score_test1 = f1_score(Y_test, Y_test_pred1)\n",
    "f1score_test2 = f1_score(Y_test, Y_test_pred2)\n",
    "f1score_test3 = f1_score(Y_test, Y_test_pred3)\n",
    "\n",
    "# 将评价指标存储在字典中\n",
    "results_train = {\n",
    "    'Model': ['Model_lr', 'Model_xgb', 'Model_mlp'],\n",
    "    'Accuracy (train)': [accuracy_train1, accuracy_train2, accuracy_train3],\n",
    "    'Precision (train)': [precision_train1, precision_train2, precision_train3],\n",
    "    'Recall (train)': [recall_train1, recall_train2, recall_train3],\n",
    "    'F1 score (train)': [f1score_train1, f1score_train2, f1score_train3],\n",
    "}\n",
    "results_test = {\n",
    "    'Model': ['Model_lr', 'Model_xgb', 'Model_mlp'],\n",
    "    'Accuracy (test)': [accuracy_test1, accuracy_test2, accuracy_test3],\n",
    "    'Precision (test)': [precision_test1, precision_test2, precision_test3],\n",
    "    'Recall (test)': [recall_test1, recall_test2, recall_test3],\n",
    "    'F1 score (test)': [f1score_test1, f1score_test2, f1score_test3],\n",
    "}\n",
    "# 将字典转换为 Pandas 数据框\n",
    "df_results_train = pd.DataFrame(results_train)\n",
    "df_results_test = pd.DataFrame(results_test)\n",
    "\n",
    "# 打印结果\n",
    "print(df_results_train)\n",
    "print(df_results_test)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 将三个模型预测准确的样本选出来分别放入一个样本集中，用于后续可解释性方法对比分析\n",
    "1. 用训练好的模型预测剩余样本\n",
    "2. 将所有样本（训练集、测试集、预测集）预测概率与是否预测正确输出，并于样本编号匹配\n",
    "3. 挑选出预测正确的样本\n",
    "4. 用不同可解释性方法对不同模型预测正确的样本进行可解释性分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将训练、测试、预测结果与输入一起保存到output文件中\n",
    "# 训练集\n",
    "output_train_lr = pd.concat([X_train_orgin, Y_train_orgin, pd.Series(model_lr.predict_proba(X_train)[:,1], index=X_train_orgin.index,name='probability_1')], axis=1) # 保留预测为1的概率\n",
    "outpt_train_xgb = pd.concat([X_train_orgin, Y_train_orgin, pd.Series(model_xgb.predict_proba(X_train)[:,1], index=X_train_orgin.index,name='probability_1')], axis=1) # 保留预测为1的概率\n",
    "output_train_mlp = pd.concat([X_train_orgin, Y_train_orgin, pd.Series(model_mlp.predict_proba(X_train)[:,1], index=X_train_orgin.index, name='probability_1')], axis=1) # 保留预测为1的概率\n",
    "\n",
    "# 测试集\n",
    "output_test_lr = pd.concat([X_test_orgin, Y_test_orgin, pd.Series(model_lr.predict_proba(X_test)[:,1], index=X_test_orgin.index,name='probability_1')], axis=1) # 保留预测为1的概率\n",
    "output_test_xgb = pd.concat([X_test_orgin, Y_test_orgin, pd.Series(model_xgb.predict_proba(X_test)[:,1], index=X_test_orgin.index,name='probability_1')], axis=1) # 保留预测为1的概率\n",
    "output_test_mlp = pd.concat([X_test_orgin, Y_test_orgin, pd.Series(model_mlp.predict_proba(X_test)[:,1], index=X_test_orgin.index, name='probability_1')], axis=1) # 保留预测为1的概率\n",
    "\n",
    "# 预测集\n",
    "output_pred_lr = pd.concat([df2, pd.Series(model_lr.predict_proba(X_pred)[:,1], index=df2.index,name='probability_1')], axis=1) # 保留预测为1的概率\n",
    "output_pred_xgb = pd.concat([df2, pd.Series(model_xgb.predict_proba(X_pred)[:,1], index=df2.index,name='probability_1')], axis=1) # 保留预测为1的概率\n",
    "output_pred_mlp = pd.concat([df2, pd.Series(model_mlp.predict_proba(X_pred)[:,1], index=df2.index, name='probability_1')], axis=1) # 保留预测为1的概率\n",
    "\n",
    "\n",
    "# predicted列为预测结果，0为未被淹，1为被淹\n",
    "# 训练集\n",
    "output_train_lr['predicted'] = (output_train_lr['probability_1'] >= 0.5).astype(int)\n",
    "outpt_train_xgb['predicted'] = (outpt_train_xgb['probability_1'] >= 0.5).astype(int)\n",
    "output_train_mlp['predicted'] = (output_train_mlp['probability_1'] >= 0.5).astype(int)\n",
    "\n",
    "# 测试集\n",
    "output_test_lr['predicted'] = (output_test_lr['probability_1'] >= 0.5).astype(int)\n",
    "output_test_xgb['predicted'] = (output_test_xgb['probability_1'] >= 0.5).astype(int)\n",
    "output_test_mlp['predicted'] = (output_test_mlp['probability_1'] >= 0.5).astype(int)\n",
    "\n",
    "# 预测集\n",
    "output_pred_lr['predicted'] = (output_pred_lr['probability_1'] >= 0.5).astype(int)\n",
    "output_pred_xgb['predicted'] = (output_pred_xgb['probability_1'] >= 0.5).astype(int)\n",
    "output_pred_mlp['predicted'] = (output_pred_mlp['probability_1'] >= 0.5).astype(int)\n",
    "\n",
    "\n",
    "# 判断预测是否正确\n",
    "# 训练集\n",
    "output_train_lr['correct'] = (output_train_lr['predicted'] == output_train_lr['label']).astype(int)\n",
    "outpt_train_xgb['correct'] = (outpt_train_xgb['predicted'] == outpt_train_xgb['label']).astype(int)\n",
    "output_train_mlp['correct'] = (output_train_mlp['predicted'] == output_train_mlp['label']).astype(int)\n",
    "\n",
    "# 测试集\n",
    "output_test_lr['correct'] = (output_test_lr['predicted'] == output_test_lr['label']).astype(int)\n",
    "output_test_xgb['correct'] = (output_test_xgb['predicted'] == output_test_xgb['label']).astype(int)\n",
    "output_test_mlp['correct'] = (output_test_mlp['predicted'] == output_test_mlp['label']).astype(int)\n",
    "\n",
    "# 预测集\n",
    "output_pred_lr['correct'] = (output_pred_lr['predicted'] == output_pred_lr['label']).astype(int)\n",
    "output_pred_xgb['correct'] = (output_pred_xgb['predicted'] == output_pred_xgb['label']).astype(int)\n",
    "output_pred_mlp['correct'] = (output_pred_mlp['predicted'] == output_pred_mlp['label']).astype(int)\n",
    "\n",
    "# 将预测正确的样本保存在output文件中\n",
    "# 训练集\n",
    "output_train_lr_correct = output_train_lr[output_train_lr['correct'] == 1]\n",
    "outpt_train_xgb_correct = outpt_train_xgb[outpt_train_xgb['correct'] == 1]\n",
    "output_train_mlp_correct = output_train_mlp[output_train_mlp['correct'] == 1]\n",
    "\n",
    "# 测试集\n",
    "output_test_lr_correct = output_test_lr[output_test_lr['correct'] == 1]\n",
    "output_test_xgb_correct = output_test_xgb[output_test_xgb['correct'] == 1]\n",
    "output_test_mlp_correct = output_test_mlp[output_test_mlp['correct'] == 1]\n",
    "\n",
    "# 预测集\n",
    "output_pred_lr_correct = output_pred_lr[output_pred_lr['correct'] == 1]\n",
    "output_pred_xgb_correct = output_pred_xgb[output_pred_xgb['correct'] == 1]\n",
    "output_pred_mlp_correct = output_pred_mlp[output_pred_mlp['correct'] == 1]\n",
    "\n",
    "# 保存到CSV文件中\n",
    "# 测试集\n",
    "output_train_lr_correct.to_csv('/workspaces/Interpretable_ML_UFSM/Interpretable_ML_for_UFSM/output/output_train_lr_correct.csv', index=False)\n",
    "outpt_train_xgb_correct.to_csv('/workspaces/Interpretable_ML_UFSM/Interpretable_ML_for_UFSM/output/output_train_xgb_correct.csv', index=False)\n",
    "output_train_mlp_correct.to_csv('/workspaces/Interpretable_ML_UFSM/Interpretable_ML_for_UFSM/output/output_train_mlp_correct.csv', index=False)\n",
    "\n",
    "# 测试集\n",
    "output_test_lr_correct.to_csv('/workspaces/Interpretable_ML_UFSM/Interpretable_ML_for_UFSM/output/output_test_lr_correct.csv', index=False)\n",
    "output_test_xgb_correct.to_csv('/workspaces/Interpretable_ML_UFSM/Interpretable_ML_for_UFSM/output/output_test_xgb_correct.csv', index=False)\n",
    "output_test_mlp_correct.to_csv('/workspaces/Interpretable_ML_UFSM/Interpretable_ML_for_UFSM/output/output_test_mlp_correct.csv', index=False)\n",
    "\n",
    "# 预测集\n",
    "output_pred_lr_correct.to_csv('/workspaces/Interpretable_ML_UFSM/Interpretable_ML_for_UFSM/output/output_pred_lr_correct.csv', index=False)\n",
    "output_pred_xgb_correct.to_csv('/workspaces/Interpretable_ML_UFSM/Interpretable_ML_for_UFSM/output/output_pred_xgb_correct.csv', index=False)\n",
    "output_pred_mlp_correct.to_csv('/workspaces/Interpretable_ML_UFSM/Interpretable_ML_for_UFSM/output/output_pred_mlp_correct.csv', index=False)\n",
    "\n",
    "# 将测试集、训练集、预测集结果预测正确的样本保存在一个文件中\n",
    "output_pred_lr_correct_all = pd.concat([output_train_lr_correct, output_test_lr_correct, output_pred_lr_correct], axis=0)\n",
    "output_pred_xgb_correct_all = pd.concat([outpt_train_xgb_correct, output_test_xgb_correct, output_pred_xgb_correct], axis=0)\n",
    "output_pred_mlp_correct_all = pd.concat([output_train_mlp_correct, output_test_mlp_correct, output_pred_mlp_correct], axis=0)\n",
    "\n",
    "# 保存到CSV文件中\n",
    "output_pred_lr_correct_all.to_csv('/workspaces/Interpretable_ML_UFSM/Interpretable_ML_for_UFSM/output/all_output_pred_lr_correct.csv', index=False)\n",
    "output_pred_xgb_correct_all.to_csv('/workspaces/Interpretable_ML_UFSM/Interpretable_ML_for_UFSM/output/all_output_pred_xgb_correct.csv', index=False)\n",
    "output_pred_mlp_correct_all.to_csv('/workspaces/Interpretable_ML_UFSM/Interpretable_ML_for_UFSM/output/all_output_pred_mlp_correct.csv', index=False)\n",
    "\n",
    "# 保存到CSV文件中\n",
    "output_train_lr.to_csv('output_train_lr.csv', index=False)\n",
    "outpt_train_xgb.to_csv('output_train_xgb.csv', index=False)\n",
    "output_train_mlp.to_csv('output_train_mlp.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
